{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API\n",
    "from flask import Flask, jsonify\n",
    "from flask import request\n",
    "from flasgger import Swagger, LazyString, LazyJSONEncoder\n",
    "from flasgger import swag_from\n",
    "\n",
    "#Cleansing\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import demoji\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "#SKLearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#defination of data test, train, and validation\n",
    "df_train = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df_valid = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df_test = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df = df_train._append(df_valid, ignore_index=True)\n",
    "\n",
    "df.columns =['text', 'label']\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "#ChangeAlayPath\n",
    "df_kbbi = pd.read_csv('KamusAlayIvan.csv', header=None, encoding='ISO-8859-1', names=['TIDAKBAKU', 'BAKU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DefinitionCleansingFunction\n",
    "def removechars(text):\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))','',text)\n",
    "    text = re.sub('\\d', '', text)\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "##Stopwords in RemoveChars\n",
    "    text = re.sub('di','',text) \n",
    "    text = re.sub('yang','',text) \n",
    "    text = re.sub('dan','',text) \n",
    "    text = re.sub('nya','',text) \n",
    "    text = re.sub('saya','',text)\n",
    "    text = re.sub('ini','',text)\n",
    "    text = re.sub('itu','',text)\n",
    "    text = re.sub('aku','',text)\n",
    "    text = re.sub('kamu','',text)\n",
    "    text = re.sub('th','',text)\n",
    "    return text\n",
    "\n",
    "def changealay(text):\n",
    "    alay = dict(zip(df_kbbi['TIDAKBAKU'], df_kbbi['BAKU']))\n",
    "    text = ' '.join([alay[word] if word in alay else word for word in text.split(' ')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CallingCleansingFunction\n",
    "\n",
    "def cleaning(text):\n",
    "    text = removechars(text)\n",
    "    text = changealay(text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df.columns =['text', 'label']\n",
    "sentiment = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
       "...                                                  ...       ...\n",
       "10995                                       tidak kecewa  positive\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  positive\n",
       "10997        hormati partai-partai yang telah berkoalisi   neutral\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative\n",
       "10999  meskipun sering belanja ke yogya di riau junct...  positive\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction TFIDF Selesai\n",
      "Training selesai\n",
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.81      0.79       687\n",
      "     neutral       0.78      0.66      0.71       230\n",
      "    positive       0.90      0.91      0.90      1283\n",
      "\n",
      "    accuracy                           0.85      2200\n",
      "   macro avg       0.82      0.79      0.80      2200\n",
      "weighted avg       0.85      0.85      0.85      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(df['text'])\n",
    "\n",
    "x = tfidf_vect.transform(df['text'])\n",
    "print('Feature Extraction TFIDF Selesai')\n",
    "\n",
    "#######################\n",
    "\n",
    "pickle.dump(tfidf_vect, open('tfidf_vect.pkl', 'wb'))\n",
    "classes = df['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, classes, test_size = 0.2, stratify=classes)\n",
    "model = MLPClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print ('Training selesai')\n",
    "\n",
    "#################\n",
    "\n",
    "pickle.dump(model, open('model.p', 'wb'))\n",
    "test = model.predict(x_test)\n",
    "\n",
    "print (\"Testing selesai\")\n",
    "\n",
    "print(classification_report(y_test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:\n",
      "\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "original_text =  '''\n",
    "ulama sehat\n",
    "'''\n",
    "\n",
    "# Feature Extraction\n",
    "text = tfidf_vect.transform([cleaning(original_text)])\n",
    "\n",
    "# Kita prediksi sentimennya\n",
    "result = model.predict(text)[0]\n",
    "print(\"Sentiment:\")\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99902434e-01, 9.73201418e-05, 2.45499679e-07]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.68      0.69       680\n",
      "     neutral       1.00      0.15      0.27       239\n",
      "    positive       0.80      0.95      0.87      1281\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.84      0.59      0.61      2200\n",
      "weighted avg       0.79      0.78      0.75      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.67      0.71       706\n",
      "     neutral       0.98      0.22      0.36       220\n",
      "    positive       0.81      0.96      0.87      1274\n",
      "\n",
      "    accuracy                           0.79      2200\n",
      "   macro avg       0.84      0.62      0.65      2200\n",
      "weighted avg       0.80      0.79      0.77      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.65      0.69       682\n",
      "     neutral       0.98      0.21      0.34       215\n",
      "    positive       0.80      0.95      0.87      1303\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.84      0.60      0.63      2200\n",
      "weighted avg       0.79      0.78      0.76      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.68      0.70       698\n",
      "     neutral       0.98      0.18      0.31       229\n",
      "    positive       0.80      0.95      0.87      1273\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.83      0.60      0.63      2200\n",
      "weighted avg       0.80      0.78      0.76      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.71      0.72       670\n",
      "     neutral       0.97      0.16      0.27       245\n",
      "    positive       0.82      0.96      0.88      1285\n",
      "\n",
      "    accuracy                           0.79      2200\n",
      "   macro avg       0.84      0.61      0.62      2200\n",
      "weighted avg       0.81      0.79      0.76      2200\n",
      "\n",
      "======================================================\n",
      "\n",
      "\n",
      "\n",
      "Rata-rata Accuracy:  0.7852727272727273\n"
     ]
    }
   ],
   "source": [
    "# Untuk lebih menyakinkan lagi, kita juga bisa melakukan \"Cross Validation\"\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = classes\n",
    "\n",
    "for iteration, data in enumerate(kf.split(x), start=1):\n",
    "\n",
    "    data_train   = x[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test    = x[data[1]]\n",
    "    target_test  = y[data[1]]\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    # clf = svm.SVC(gamma=0.01, C=100., probability=True)\n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    preds = clf.predict(data_test)\n",
    "\n",
    "    # for the current fold only    \n",
    "    accuracy = accuracy_score(target_test,preds)\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(target_test,preds))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo  user anjing rt gws apa  kabar       \n"
     ]
    }
   ],
   "source": [
    "print(cleaning('Halo, user ANJING RT gws Apa ?Kabar ðŸ˜‚ ðŸ¤£ ðŸ¥²?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung  miliki oleh pengusaha pabrik tahu  sud...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus   memberi hujjah partai apa ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis  jalan sumatera bandung   tem...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia  ri  saat unboxing paket  baran...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh   ja mahasiswa jangan sombong dong   kasih...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan  apalagi kepiting  menyenang...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai partai  telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi  tol pasteur sudah macet parah   bik...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya  riau junctio...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      warung  miliki oleh pengusaha pabrik tahu  sud...  positive\n",
       "1      mohon ulama lurus   memberi hujjah partai apa ...   neutral\n",
       "2      lokasi strategis  jalan sumatera bandung   tem...  positive\n",
       "3      betapa bahagia  ri  saat unboxing paket  baran...  positive\n",
       "4      duh   ja mahasiswa jangan sombong dong   kasih...  negative\n",
       "...                                                  ...       ...\n",
       "10995                                       tidak kecewa  positive\n",
       "10996  enak rasa masakan  apalagi kepiting  menyenang...  positive\n",
       "10997            hormati partai partai  telah berkoalisi   neutral\n",
       "10998  pagi pagi  tol pasteur sudah macet parah   bik...  negative\n",
       "10999  meskipun sering belanja ke yogya  riau junctio...  positive\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction TFIDF Selesai\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(df['text'])\n",
    "\n",
    "x = tfidf_vect.transform(df['text'])\n",
    "print('Feature Extraction TFIDF Selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(tfidf_vect, open('tfidf_vect.pkl', 'wb'))\n",
    "classes = df['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, classes, test_size = 0.2, stratify=classes)\n",
    "model = MLPClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print ('Training selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1         neutral\n",
       "2        positive\n",
       "3        positive\n",
       "4        negative\n",
       "           ...   \n",
       "10995    positive\n",
       "10996    positive\n",
       "10997     neutral\n",
       "10998    negative\n",
       "10999    positive\n",
       "Name: label, Length: 11000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79       687\n",
      "     neutral       0.81      0.74      0.78       230\n",
      "    positive       0.88      0.91      0.89      1283\n",
      "\n",
      "    accuracy                           0.85      2200\n",
      "   macro avg       0.83      0.81      0.82      2200\n",
      "weighted avg       0.85      0.85      0.85      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('model.p', 'wb'))\n",
    "test = model.predict(x_test)\n",
    "\n",
    "print (\"Testing selesai\")\n",
    "\n",
    "print(classification_report(y_test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:\n",
      "\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "original_text =  '''\n",
    "ulama sakit\n",
    "'''\n",
    "\n",
    "# Feature Extraction\n",
    "count_vect = TfidfVectorizer()\n",
    "text = tfidf_vect.transform([cleaning(original_text)])\n",
    "\n",
    "# Kita prediksi sentimennya\n",
    "result = model.predict(text)[0]\n",
    "print(\"Sentiment:\")\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.84681205e-01, 1.44631028e-02, 8.55692018e-04]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.68      0.69       680\n",
      "     neutral       1.00      0.15      0.26       239\n",
      "    positive       0.80      0.94      0.87      1281\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.83      0.59      0.61      2200\n",
      "weighted avg       0.79      0.78      0.75      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.68      0.71       706\n",
      "     neutral       0.98      0.23      0.37       220\n",
      "    positive       0.81      0.95      0.87      1274\n",
      "\n",
      "    accuracy                           0.79      2200\n",
      "   macro avg       0.84      0.62      0.65      2200\n",
      "weighted avg       0.81      0.79      0.77      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.66      0.69       682\n",
      "     neutral       0.98      0.23      0.37       215\n",
      "    positive       0.80      0.94      0.87      1303\n",
      "\n",
      "    accuracy                           0.79      2200\n",
      "   macro avg       0.84      0.61      0.64      2200\n",
      "weighted avg       0.80      0.79      0.76      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.68      0.70       698\n",
      "     neutral       0.98      0.19      0.32       229\n",
      "    positive       0.80      0.94      0.87      1273\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.83      0.60      0.63      2200\n",
      "weighted avg       0.79      0.78      0.76      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.73      0.73       670\n",
      "     neutral       1.00      0.17      0.29       245\n",
      "    positive       0.82      0.95      0.88      1285\n",
      "\n",
      "    accuracy                           0.80      2200\n",
      "   macro avg       0.85      0.62      0.63      2200\n",
      "weighted avg       0.81      0.80      0.77      2200\n",
      "\n",
      "======================================================\n",
      "\n",
      "\n",
      "\n",
      "Rata-rata Accuracy:  0.7869090909090909\n"
     ]
    }
   ],
   "source": [
    "# Untuk lebih menyakinkan lagi, kita juga bisa melakukan \"Cross Validation\"\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = classes\n",
    "\n",
    "for iteration, data in enumerate(kf.split(x), start=1):\n",
    "\n",
    "    data_train   = x[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test    = x[data[1]]\n",
    "    target_test  = y[data[1]]\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    # clf = svm.SVC(gamma=0.01, C=100., probability=True)\n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    preds = clf.predict(data_test)\n",
    "\n",
    "    # for the current fold only    \n",
    "    accuracy = accuracy_score(target_test,preds)\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(target_test,preds))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
