{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hivan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hivan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#API\n",
    "from flask import Flask, jsonify\n",
    "from flask import request\n",
    "from flasgger import Swagger, LazyString, LazyJSONEncoder\n",
    "from flasgger import swag_from\n",
    "\n",
    "#Cleansing\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import demoji\n",
    "import pickle\n",
    "\n",
    "#Stemmer\n",
    "from pathlib import Path\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#CallFile\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "id_stopword_dict = pd.read_csv('stopwordbahasa.csv', header=None)\n",
    "id_stopword_dict = id_stopword_dict.rename(columns={0: 'stopword'})\n",
    "\n",
    "df_kbbi = pd.read_csv('new_kamusalay.csv', header=None, encoding='ISO-8859-1', names=['TIDAKBAKU', 'BAKU'])\n",
    "\n",
    "#defination of data test, train, and validation\n",
    "df_train = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df_valid = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df_test = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df = df_train._append(df_valid, ignore_index=True)\n",
    "\n",
    "df.columns =['text', 'label']\n",
    "sentiment = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    dem = demoji.findall(text)\n",
    "    for demoj in dem.keys():\n",
    "        text = text.replace(demoj, '')\n",
    "    return text\n",
    "\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def removechars(text):\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    text = re.sub('rt',' ',text) \n",
    "    text = re.sub('user',' ',text) \n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text)\n",
    "    text = re.sub('xf0',' ',text) \n",
    "    text = re.sub('x9f',' ',text) \n",
    "    text = re.sub('x98',' ',text) \n",
    "    text = re.sub('x82',' ',text) \n",
    "    text = re.sub('x84',' ',text) \n",
    "    text = re.sub('x86',' ',text) \n",
    "    text = re.sub('x8f',' ',text) \n",
    "    text = re.sub('xa4',' ',text)\n",
    "    text = re.sub('xa2',' ',text)\n",
    "    text = re.sub('x8b',' ',text)\n",
    "    return text\n",
    "\n",
    "def changealay(text):\n",
    "    alay = dict(zip(df_kbbi['TIDAKBAKU'], df_kbbi['BAKU']))\n",
    "    text = ' '.join([alay[word] if word in alay else word for word in text.split(' ')])\n",
    "    return text\n",
    "\n",
    "\n",
    "##################################################################\n",
    "def remove_stopword(text):\n",
    "    text = ' '.join(['' if word in id_stopword_dict.stopword.values else word for word in text.split(' ')])\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def stemming(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "def cleaning(text):\n",
    "    text = remove_emoji(text)\n",
    "    text = removechars(text)\n",
    "    text = lowercase(text)\n",
    "    text = changealay(text)\n",
    "    text = stemming(text) \n",
    "    text = remove_stopword(text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocess.txt\", delimiter = \"\\t\", header=None)\n",
    "df.columns =['text', 'label']\n",
    "sentiment = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2      lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...  negative\n",
       "...                                                  ...       ...\n",
       "10995                                       tidak kecewa  positive\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...  positive\n",
       "10997        hormati partai-partai yang telah berkoalisi   neutral\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...  negative\n",
       "10999  meskipun sering belanja ke yogya di riau junct...  positive\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vect = TfidfVectorizer()\n",
    "# tfidf_vect.fit(df['text'])\n",
    "\n",
    "# x = tfidf_vect.transform(df['text'])\n",
    "# print('Feature Extraction TFIDF Selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(tfidf_vect, open('tfidf_vect.pkl', 'wb'))\n",
    "# classes = df['label']\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, classes, test_size = 0.2, stratify=classes)\n",
    "# model = MLPClassifier()\n",
    "# model.fit(x_train, y_train)\n",
    "\n",
    "# print ('Training selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model, open('model.p', 'wb'))\n",
    "# test = model.predict(x_test)\n",
    "\n",
    "# print (\"Testing selesai\")\n",
    "\n",
    "# print(classification_report(y_test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_text =  '''\n",
    "# ulama sehat\n",
    "# '''\n",
    "\n",
    "# # Feature Extraction\n",
    "# text = tfidf_vect.transform([cleaning(original_text)])\n",
    "\n",
    "# # Kita prediksi sentimennya\n",
    "# result = model.predict(text)[0]\n",
    "# print(\"Sentiment:\")\n",
    "# print()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict_proba(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Untuk lebih menyakinkan lagi, kita juga bisa melakukan \"Cross Validation\"\n",
    "\n",
    "# kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "# accuracies = []\n",
    "\n",
    "# y = classes\n",
    "\n",
    "# for iteration, data in enumerate(kf.split(x), start=1):\n",
    "\n",
    "#     data_train   = x[data[0]]\n",
    "#     target_train = y[data[0]]\n",
    "\n",
    "#     data_test    = x[data[1]]\n",
    "#     target_test  = y[data[1]]\n",
    "\n",
    "#     clf = MultinomialNB()\n",
    "#     # clf = svm.SVC(gamma=0.01, C=100., probability=True)\n",
    "#     clf.fit(data_train,target_train)\n",
    "\n",
    "#     preds = clf.predict(data_test)\n",
    "\n",
    "#     # for the current fold only    \n",
    "#     accuracy = accuracy_score(target_test,preds)\n",
    "\n",
    "#     print(\"Training ke-\", iteration)\n",
    "#     print(classification_report(target_test,preds))\n",
    "#     print(\"======================================================\")\n",
    "\n",
    "#     accuracies.append(accuracy)\n",
    "\n",
    "# # this is the average accuracy over all folds\n",
    "# average_accuracy = np.mean(accuracies)\n",
    "\n",
    "# print()\n",
    "# print()\n",
    "# print()\n",
    "# print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung milik usaha pabrik puluh kenal putih ba...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus k212 mmbri hujjah ai diwlh s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis jalan sumatra bandung nya nya...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya unboxing paket barang nya b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aduh mahasiswa sombong kasih kakak kuning ajar...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>kecewa</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak masakan nya kepiting senang pilih kepitin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormat ai ai koalisi</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi tol pasteur macet parah bikin jengkel</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>belanja yogyakarta riau junction pe kali lihat...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      warung milik usaha pabrik puluh kenal putih ba...  positive\n",
       "1      mohon ulama lurus k212 mmbri hujjah ai diwlh s...   neutral\n",
       "2      lokasi strategis jalan sumatra bandung nya nya...  positive\n",
       "3      betapa bahagia nya unboxing paket barang nya b...  positive\n",
       "4      aduh mahasiswa sombong kasih kakak kuning ajar...  negative\n",
       "...                                                  ...       ...\n",
       "10995                                             kecewa  positive\n",
       "10996  enak masakan nya kepiting senang pilih kepitin...  positive\n",
       "10997                               hormat ai ai koalisi   neutral\n",
       "10998    pagi pagi tol pasteur macet parah bikin jengkel  negative\n",
       "10999  belanja yogyakarta riau junction pe kali lihat...  positive\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction TFIDF Selesai\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(df['text'])\n",
    "\n",
    "x = tfidf_vect.transform(df['text'])\n",
    "print('Feature Extraction TFIDF Selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(tfidf_vect, open('tfidf_vect.pkl', 'wb'))\n",
    "classes = df['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, classes, test_size = 0.2, stratify=classes)\n",
    "model = MLPClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print ('Training selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1         neutral\n",
       "2        positive\n",
       "3        positive\n",
       "4        negative\n",
       "           ...   \n",
       "10995    positive\n",
       "10996    positive\n",
       "10997     neutral\n",
       "10998    negative\n",
       "10999    positive\n",
       "Name: label, Length: 11000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.73      0.70       687\n",
      "     neutral       0.75      0.49      0.59       230\n",
      "    positive       0.84      0.86      0.85      1283\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.76      0.69      0.71      2200\n",
      "weighted avg       0.78      0.78      0.78      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('model.p', 'wb'))\n",
    "test = model.predict(x_test)\n",
    "\n",
    "print (\"Testing selesai\")\n",
    "\n",
    "print(classification_report(y_test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:\n",
      "\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "original_text =  '''\n",
    "ulama sakit\n",
    "'''\n",
    "\n",
    "# Feature Extraction\n",
    "count_vect = TfidfVectorizer()\n",
    "text = tfidf_vect.transform([cleaning(original_text)])\n",
    "\n",
    "# Kita prediksi sentimennya\n",
    "result = model.predict(text)[0]\n",
    "print(\"Sentiment:\")\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.50499959e-03, 6.05021573e-06, 9.92488950e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke- 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.74      0.73       680\n",
      "     neutral       0.74      0.54      0.63       239\n",
      "    positive       0.85      0.88      0.86      1281\n",
      "\n",
      "    accuracy                           0.80      2200\n",
      "   macro avg       0.77      0.72      0.74      2200\n",
      "weighted avg       0.80      0.80      0.80      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.71      0.71       706\n",
      "     neutral       0.70      0.55      0.62       220\n",
      "    positive       0.83      0.86      0.85      1274\n",
      "\n",
      "    accuracy                           0.78      2200\n",
      "   macro avg       0.75      0.71      0.72      2200\n",
      "weighted avg       0.78      0.78      0.78      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.74      0.72       682\n",
      "     neutral       0.78      0.55      0.64       215\n",
      "    positive       0.85      0.86      0.86      1303\n",
      "\n",
      "    accuracy                           0.80      2200\n",
      "   macro avg       0.78      0.72      0.74      2200\n",
      "weighted avg       0.80      0.80      0.79      2200\n",
      "\n",
      "======================================================\n",
      "Training ke- 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.74      0.72       698\n",
      "     neutral       0.72      0.50      0.59       229\n",
      "    positive       0.85      0.88      0.86      1273\n",
      "\n",
      "    accuracy                           0.79      2200\n",
      "   macro avg       0.76      0.71      0.73      2200\n",
      "weighted avg       0.79      0.79      0.79      2200\n",
      "\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "# Untuk lebih menyakinkan lagi, kita juga bisa melakukan \"Cross Validation\"\n",
    "\n",
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = classes\n",
    "\n",
    "for iteration, data in enumerate(kf.split(x), start=1):\n",
    "\n",
    "    data_train   = x[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test    = x[data[1]]\n",
    "    target_test  = y[data[1]]\n",
    "\n",
    "    clf = MLPClassifier()\n",
    "    # clf = svm.SVC(gamma=0.01, C=100., probability=True)\n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    preds = clf.predict(data_test)\n",
    "\n",
    "    # for the current fold only    \n",
    "    accuracy = accuracy_score(target_test,preds)\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(target_test,preds))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
